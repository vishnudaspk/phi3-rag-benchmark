# ğŸ§© Phi-3 RAG Benchmark

This repository benchmarks **Microsoftâ€™s Phi-3 Mini (4K Instruct)** model under different **quantization settings** to analyze inference speed, GPU memory utilization, and load behavior.
It provides a reproducible pipeline to measure model performance using Python, CUDA, and PyTorch-based inference workflows.

---

## ğŸš€ Project Overview

The benchmark aims to evaluate **Phi-3 Mini 4K Instruct** for **Retrieval-Augmented Generation (RAG)** and general inference workloads.
The tests cover multiple quantization formats including:

* ğŸŸ¢ 4-bit
* ğŸŸ¡ 8-bit
* ğŸ”µ 16-bit
* ğŸ”´ 32-bit

Each configuration was analyzed for:

* â±ï¸ Inference Time
* ğŸ’¾ GPU Memory (start/end)
* ğŸ”‹ GPU Load (start/end)
* ğŸ§® NVSMI Metrics (memory & load)

---

## ğŸ–¥ï¸ System Specifications

| Component        | Specification                         |
| ---------------- | ------------------------------------- |
| **Device**       | Lenovo Legion Slim 7i                 |
| **Processor**    | IntelÂ® Coreâ„¢ i9-13900H                |
| **GPU**          | NVIDIA GeForce RTX 4060 (8 GB VRAM)   |
| **CUDA Version** | 12.1                                  |
| **OS**           | Windows 11 (PowerShell + VSCode)      |
| **Python Env**   | Conda (Python 3.10, `rag_server` environment) |

---

## ğŸ“‚ Repository Structure

```
Phi-3-mini-4k-instruct/
â”‚
â”œâ”€â”€â”€results/
â”‚   â”œâ”€â”€ Figure_1.png
â”‚   â”œâ”€â”€ Figure_3.png
â”‚   â”œâ”€â”€ phy3_inference_graph.png
â”‚   â””â”€â”€ analysis/
â”‚       â”œâ”€â”€ phi3_baseline_combined.csv
â”‚       â””â”€â”€ phi3_baseline_summary.csv
â”‚
â”œâ”€â”€â”€scripts/
â”‚   â”œâ”€â”€ Phi3_inference_demo.py
â”‚   â”œâ”€â”€ phi3_server.py
â”‚   â”œâ”€â”€ phi3_baseline.py
â”‚   â”œâ”€â”€ analyze_phi3_baselines.py
â”‚   â””â”€â”€ graph.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup_env.bat
â””â”€â”€ .gitignore
```

---

## ğŸ“Š Results & Visualizations

Below are the benchmark visualizations generated from `results/analysis/phi3_baseline_summary.csv` and `phi3_baseline_combined.csv`.

### ğŸ”¹ Performance Metrics Visualization
![Performance Graph](results/graph.png)

### ğŸ”¹ Quantization Performance Comparison
![Quantization Performance](results/performance_quantization.png)

### ğŸ”¹ Phi-3 Inference Comparison
![Phi3 Inference Graph](results/phy3_inference_graph.png)

---

## ğŸ§ª How to Reproduce

### 1ï¸âƒ£ Setup Environment

```bash
conda create -n rag_server python=3.10 -y
conda activate rag_server
pip install -r requirements.txt
```
### 2ï¸âƒ£ Run Baseline Tests

```bash
python scripts/phi3_server.py
```

### 3ï¸âƒ£ Run Baseline Tests

```bash
python scripts/phi3_baseline.py
```

### 4ï¸âƒ£ Analyze Results

```bash
python scripts/analyze_phi3_baselines.py
```

### 5ï¸âƒ£ Generate Graphs

```bash
python scripts/graph.py
```

All generated plots will be saved under `results/`.

---

## âš™ï¸ Technical Notes

* **Model tested:** Phi-3 Mini (4K Instruct)
* **Inference framework:** PyTorch + CUDA
* **Quantization:** handled using `bitsandbytes` and `torch.quantization`
* **Benchmark metrics collected with:**

  * `GPUtil` for memory/load tracking
  * `nvidia-smi` CLI for system-level metrics

---

## ğŸ“ˆ Observations

| Quantization | Inference Time (sec) | GPU Memory Start (MB) | GPU Memory End (MB) | GPU Load End (%) |
| ------------ | -------------------- | --------------------- | ------------------- | ---------------- |
| 4-bit        | 358.05               | 6953.8                | 7101.6              | 59.4             |
| 8-bit        | 22.27                | 4932.4                | 4990.0              | 36.2             |
| 16-bit       | 326.66               | 6891.6                | 7008.4              | 70.6             |
| 32-bit       | 381.39               | 6855.0                | 6964.0              | 67.6             |

ğŸ§© **8-bit quantization demonstrated the best trade-off between inference speed and GPU load.**

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” feel free to use and modify with attribution.

---

## ğŸ™Œ Credits

Developed by **Vishnu Das P K**
GPU Benchmarking, Analysis, and Visualization for Phi-3 Mini 4K Instruct (RAG Pipeline Testing)
ğŸ’¡ Repository: `phi3-rag-benchmark`